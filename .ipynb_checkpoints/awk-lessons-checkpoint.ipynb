{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [The Unix School: awk](https://www.theunixschool.com/p/awk-sed.html)\n",
    "- Read & split file contents\n",
    "- Pass arguments or shell variables\n",
    "- Pattern matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: awk [POSIX or GNU style options] -f progfile [--] file ...\n",
      "Usage: awk [POSIX or GNU style options] [--] 'program' file ...\n",
      "POSIX options:\t\tGNU long options: (standard)\n",
      "\t-f progfile\t\t--file=progfile\n",
      "\t-F fs\t\t\t--field-separator=fs\n",
      "\t-v var=val\t\t--assign=var=val\n",
      "Short options:\t\tGNU long options: (extensions)\n",
      "\t-b\t\t\t--characters-as-bytes\n",
      "\t-c\t\t\t--traditional\n",
      "\t-C\t\t\t--copyright\n",
      "\t-d[file]\t\t--dump-variables[=file]\n",
      "\t-D[file]\t\t--debug[=file]\n",
      "\t-e 'program-text'\t--source='program-text'\n",
      "\t-E file\t\t\t--exec=file\n",
      "\t-g\t\t\t--gen-pot\n",
      "\t-h\t\t\t--help\n",
      "\t-i includefile\t\t--include=includefile\n",
      "\t-l library\t\t--load=library\n",
      "\t-L[fatal|invalid|no-ext]\t--lint[=fatal|invalid|no-ext]\n",
      "\t-M\t\t\t--bignum\n",
      "\t-N\t\t\t--use-lc-numeric\n",
      "\t-n\t\t\t--non-decimal-data\n",
      "\t-o[file]\t\t--pretty-print[=file]\n",
      "\t-O\t\t\t--optimize\n",
      "\t-p[file]\t\t--profile[=file]\n",
      "\t-P\t\t\t--posix\n",
      "\t-r\t\t\t--re-interval\n",
      "\t-s\t\t\t--no-optimize\n",
      "\t-S\t\t\t--sandbox\n",
      "\t-t\t\t\t--lint-old\n",
      "\t-V\t\t\t--version\n",
      "\n",
      "To report bugs, see node `Bugs' in `gawk.info'\n",
      "which is section `Reporting Problems and Bugs' in the\n",
      "printed version.  This same information may be found at\n",
      "https://www.gnu.org/software/gawk/manual/html_node/Bugs.html.\n",
      "PLEASE do NOT try to report bugs by posting in comp.lang.awk,\n",
      "or by using a web forum such as Stack Overflow.\n",
      "\n",
      "gawk is a pattern scanning and processing language.\n",
      "By default it reads standard input and writes standard output.\n",
      "\n",
      "Examples:\n",
      "\tawk '{ sum += $1 }; END { print sum }' file\n",
      "\tawk -F: '{ print $1 }' /etc/passwd\n"
     ]
    }
   ],
   "source": [
    "!awk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNU Awk 5.1.0, API: 3.0 (GNU MPFR 4.1.0, GNU MP 6.2.1)\n",
      "Copyright (C) 1989, 1991-2020 Free Software Foundation.\n",
      "\n",
      "This program is free software; you can redistribute it and/or modify\n",
      "it under the terms of the GNU General Public License as published by\n",
      "the Free Software Foundation; either version 3 of the License, or\n",
      "(at your option) any later version.\n",
      "\n",
      "This program is distributed in the hope that it will be useful,\n",
      "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
      "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
      "GNU General Public License for more details.\n",
      "\n",
      "You should have received a copy of the GNU General Public License\n",
      "along with this program. If not, see http://www.gnu.org/licenses/.\n"
     ]
    }
   ],
   "source": [
    "!awk -W version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 1: read a file & split the contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name Domain\n",
      "Deepak Banking\n",
      "Neha Telecom\n",
      "Vijay Finance\n",
      "Guru Migration"
     ]
    }
   ],
   "source": [
    "!cat file1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name\n",
      "Deepak\n",
      "Neha\n",
      "Vijay\n",
      "Guru\n",
      "Domain\n",
      "Banking\n",
      "Telecom\n",
      "Finance\n",
      "Migration\n"
     ]
    }
   ],
   "source": [
    "# print *only* the names, then domains, in the file\n",
    "!awk '{print $1}' file1\n",
    "!awk '{print $2}' file1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deepak\n",
      "Neha\n",
      "Vijay\n",
      "Guru\n"
     ]
    }
   ],
   "source": [
    "# print the names without the header record\n",
    "# NR = line number; NR!=1 says to omit the 1st line.\n",
    "!awk 'NR!=1{print $1}' file1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name Domain\n",
      "Deepak Banking\n",
      "Neha Telecom\n",
      "Vijay Finance\n",
      "Guru Migration\n"
     ]
    }
   ],
   "source": [
    "# print entire file contents - $0 = entire line.\n",
    "!awk '{print $0}' file1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name Domain\n",
      "Deepak Banking\n",
      "Neha Telecom\n",
      "Vijay Finance\n",
      "Guru Migration\n"
     ]
    }
   ],
   "source": [
    "# another way of printing everything ('1' = true for every line.)\n",
    "!awk '1' file1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name,Domain,Expertise\n",
      "Deepak,Banking,MQ Series\n",
      "Neha,Telecom,Power Builder\n",
      "Vijay,Finance,CRM Expert\n",
      "Guru,Migration,Unix"
     ]
    }
   ],
   "source": [
    "!cat file2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name\n",
      "Deepak\n",
      "Neha\n",
      "Vijay\n",
      "Guru\n"
     ]
    }
   ],
   "source": [
    "# print 1st column of a .CSV file\n",
    "# awk uses whitespace as a default delimiter.\n",
    "# .CSV is comma delimited, so we need to specify that.\n",
    "\n",
    "!awk -F\",\" '{print $1}' file2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name Expertise\n",
      "Deepak MQ Series\n",
      "Neha Power Builder\n",
      "Vijay CRM Expert\n",
      "Guru Unix\n"
     ]
    }
   ],
   "source": [
    "# (alternate syntax using the FS variable - 1st & 3rd columns)\n",
    "!awk  '{print $1,$3}' FS=\",\" file2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deepak,MQ Series\n",
      "Neha,Power Builder\n",
      "Vijay,CRM Expert\n",
      "Guru,Unix\n"
     ]
    }
   ],
   "source": [
    "# 3rd column has multiple words, so readability is compromised.\n",
    "# use a comma to separate the output with the OFS special variable.\n",
    "# and omit the header with NR\n",
    "!awk -F\",\" 'NR!=1{print $1,$3}' OFS=\",\" file2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 2: passing arguments or shell variables to awk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name,Domain,Expertise\n",
      "Deepak,Banking,MQ Series\n",
      "Neha,Telecom,Power Builder\n",
      "Vijay,Finance,CRM Expert\n",
      "Guru,Migration,Unix"
     ]
    }
   ],
   "source": [
    "# quoting file content\n",
    "!cat file2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Name,Domain,Expertise'\n",
      "'Deepak,Banking,MQ Series'\n",
      "'Neha,Telecom,Power Builder'\n",
      "'Vijay,Finance,CRM Expert'\n",
      "'Guru,Migration,Unix'\n"
     ]
    }
   ],
   "source": [
    "!awk -v q=\"'\" '{print q $0 q}' file2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Name,Domain,Expertise\"\n",
      "\"Deepak,Banking,MQ Series\"\n",
      "\"Neha,Telecom,Power Builder\"\n",
      "\"Vijay,Finance,CRM Expert\"\n",
      "\"Guru,Migration,Unix\"\n"
     ]
    }
   ],
   "source": [
    "# double-quoting file contents\n",
    "!awk '{print q $0 q}' q='\"' file2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 3: matching file patterns in Linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medicine,200\n",
      "Grocery,500\n",
      "Rent,900\n",
      "Grocery,800\n",
      "Medicine,600"
     ]
    }
   ],
   "source": [
    "!cat file3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rent,900\n"
     ]
    }
   ],
   "source": [
    "# match only the records containing 'Rent'\n",
    "!awk '/Rent/' file3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rent,900\n"
     ]
    }
   ],
   "source": [
    "# match a pattern only in the 1st column\n",
    "!awk -F, '$1 ~ /Rent/' file3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rent,900\n"
     ]
    }
   ],
   "source": [
    "# Above also matches \"Rents\". Exact match:\n",
    "!awk -F, '$1==\"Rent\"' file3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "600\n"
     ]
    }
   ],
   "source": [
    "# print only the 2nd column for all \"Medicine\" records:\n",
    "!awk -F, '$1 == \"Medicine\"{print $2}' file3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medicine,200\n",
      "Rent,900\n",
      "Medicine,600\n"
     ]
    }
   ],
   "source": [
    "# match for patterns \"Rent\" or \"Medicine\"\n",
    "!awk '/Rent|Medicine/' file3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medicine,200\n",
      "Rent,900\n",
      "Medicine,600\n"
     ]
    }
   ],
   "source": [
    "# match for this above pattern only in the first column:\n",
    "!awk -F, '$1 ~ /Rent|Medicine/' file3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medicine,200\n",
      "Rent,900\n",
      "Medicine,600\n"
     ]
    }
   ],
   "source": [
    "# exactly match only for Rent or Medicine,\n",
    "!awk -F, '$1 ~ /^Rent$|^Medicine$/' file3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grocery,500\n",
      "Rent,900\n",
      "Grocery,800\n"
     ]
    }
   ],
   "source": [
    "# lines which does not contain the pattern Medicine:\n",
    "!awk '!/Medicine/' file3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rent,900\n",
      "Grocery,800\n",
      "Medicine,600\n"
     ]
    }
   ],
   "source": [
    "# all records whose amount is greater than 500:\n",
    "!awk -F, '$2>500' file3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medicine,200\n"
     ]
    }
   ],
   "source": [
    "# print medicine record only if it is the 1st record (&& = logical AND):\n",
    "!awk 'NR==1 && /Medicine/' file3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medicine,600\n"
     ]
    }
   ],
   "source": [
    "# all Medicine records whose amount is greater than 500:\n",
    "!awk -F, '/Medicine/ && $2>500' file3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medicine,200\n",
      "Rent,900\n",
      "Grocery,800\n",
      "Medicine,600\n"
     ]
    }
   ],
   "source": [
    "# all the Medicine records OR whose amount is greater than 600 (|| = logical OR):\n",
    "!awk -F, '/Medicine/ || $2>600' file3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 4: Join or merge lines on finding a pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START\n",
      "Unix\n",
      "Linux\n",
      "START\n",
      "Solaris\n",
      "Aix\n",
      "SCO"
     ]
    }
   ],
   "source": [
    "!cat file4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnixLinux\n",
      "SolarisAixSCO\n"
     ]
    }
   ],
   "source": [
    "# join lines after START, without a delimiter\n",
    "# - accumulate lines following START;\n",
    "# - print them before encountering the next START.\n",
    "# - command inside {} only works if line contains START.\n",
    "# - \"next\" prevents remaining part of command from being executed on START lines.\n",
    "\n",
    "!awk '/START/{if (NR!=1)print \"\";next}{printf $0}END{print \"\";}' file4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 5: grouping CSV or text file data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 6: spliting files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 7: reading files with multiple delimiters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 8: accessing awk variables in a shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 9: inserting, removing, updating CSV file data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 10: (gawk) time & date math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 11: time between datestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1,2012 12 4 21 36 48,2012 12 4 22 26 53\n",
      "P2,2012 12 4 20 36 48,2012 12 4 21 21 23\n",
      "P3,2012 12 4 18 36 48,2012 12 4 20 12 35"
     ]
    }
   ],
   "source": [
    "# file format: dates & times are separated by a space.\n",
    "# column 1 = process name\n",
    "# column 2 = process start time\n",
    "# column 3 = process end time\n",
    "!cat file11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1,2012,0 secs\n",
      "P2,2012,0 secs\n",
      "P3,2012,0 secs\n"
     ]
    }
   ],
   "source": [
    "# time difference, in seconds\n",
    "# mktime function returns Unix time for date time strings\n",
    "!awk '{d2=mktime($3);d1=mktime($2);print $1\",\"d2-d1,\"secs\";}' file11"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
